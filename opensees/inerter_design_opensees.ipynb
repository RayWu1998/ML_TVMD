{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from control import lqr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os, re\n",
    "import pandas as pd\n",
    "from matplotlib import font_manager  #matplotlib中 中文设置模块"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 输出高清图像\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import platform\n",
    "# 图像显示中文的问题，需要判断系统是windows还是苹果的\n",
    "import matplotlib\n",
    "import platform\n",
    "sys_platform = platform.platform().lower()\n",
    "if \"windows\" in sys_platform:\n",
    "    font = {\n",
    "    \"family\": \"Times New Roman\"\n",
    "    }\n",
    "    matplotlib.rc(\"font\", **font)\n",
    "else:\n",
    "    font = {\n",
    "    \"family\": \"Arial Unicode MS\"\n",
    "    }\n",
    "    matplotlib.rc(\"font\", **font)\n",
    "rc = {\"mathtext.fontset\" : \"stix\",}\n",
    "\n",
    "plt.rcParams.update(rc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('./data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/opensees_design_res.csv')\n",
    "df.info()\n",
    "df['ok'] = True\n",
    "df.loc[df[\"drift_max\"] > 1 / 200, ['ok']]=False\n",
    "df.loc[df[\"a_max\"] > 0.35 * 9.8, ['ok']]=False\n",
    "df.sample(3)\n",
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"ok\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Libs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 利用GridSearchCV选择最优参数\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特征过程"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉id,site_name,miu,zeta,kappa,gamma,alpha,\n",
    "x_label = [\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\", \"m7\", \"m8\", \"m9\", \"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\", \"k8\", \"k9\", \"c1\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\", \"c9\", \"sa1\", \"sa2\", \"sa3\", \"sa4\", \"sa5\", \"sa6\", \"sa7\", \"sa8\", \"sa9\", \"sa10\", \"sa11\", \"sa12\", \"sa13\", \"sa14\", \"sa15\", \"sa16\", \"sa17\", \"sa18\", \"sa19\", \"sa20\", \"sa21\", \"sa22\", \"sa23\", \"sa24\", \"sa25\", \"sa26\", \"sa27\", \"sa28\", \"sa29\", \"sa30\", \"sv1\", \"sv2\", \"sv3\", \"sv4\", \"sv5\", \"sv6\", \"sv7\", \"sv8\", \"sv9\", \"sv10\", \"sv11\", \"sv12\", \"sv13\", \"sv14\", \"sv15\", \"sv16\", \"sv17\", \"sv18\", \"sv19\", \"sv20\", \"sv21\", \"sv22\", \"sv23\", \"sv24\", \"sv25\", \"sv26\", \"sv27\", \"sv28\", \"sv29\", \"sv30\", \"sd1\", \"sd2\", \"sd3\", \"sd4\", \"sd5\", \"sd6\", \"sd7\", \"sd8\", \"sd9\", \"sd10\", \"sd11\", \"sd12\", \"sd13\", \"sd14\", \"sd15\", \"sd16\", \"sd17\", \"sd18\", \"sd19\", \"sd20\", \"sd21\", \"sd22\", \"sd23\", \"sd24\", \"sd25\", \"sd26\", \"sd27\", \"sd28\", \"sd29\", \"sd30\", \"sa_max\", \"sa_avg\", \"sv_max\", \"sv_avg\", \"sd_max\", \"sd_avg\", \"pga\", \"pgv\", \"pgd\", \"epa\", \"epv\", \"epd\", \"pa\", \"pv\", \"pd\", \"ic\"]\n",
    "y_label = [\"ok\"]\n",
    "X = df.loc[:, x_label].values\n",
    "y = df.loc[:, y_label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2)\n",
    "# y_test = y_test.reshape([-1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle_index = np.random.permutation(934)\n",
    "# X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = X_train\n",
    "new_X_test = X_test\n",
    "\n",
    "# normalizer = Normalizer(copy=True, norm='l2').fit(new_X_train)\n",
    "ss = StandardScaler().fit(new_X_train)\n",
    "new_X_train = ss.transform(new_X_train)\n",
    "new_X_test = ss.transform(new_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test\n",
    "# model = DecisionTreeClassifier()\n",
    "# param = {'criterion': ['gini', 'entropy'], 'max_depth': [10, 20,30,40, 50, 60,70,80,90,100], 'min_samples_leaf': [2, 3, 5, 10], 'min_impurity_decrease': [0.1, 0.2, 0.5]}\n",
    "# grid = GridSearchCV(model, param_grid=param, cv=5)\n",
    "# grid.fit(new_X_train, y_train)\n",
    "# print('最优分类器:', grid.best_estimator_)\n",
    "# print('最优超参数：', grid.best_params_)\n",
    "# print('最优分数:', grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=3)\n",
    "print(rfc)\n",
    "rfc.fit(new_X_train, y_train)\n",
    "y_pre_rfc = rfc.predict(new_X_test)\n",
    "\n",
    "print('正确标签：', y_test)\n",
    "print('预测结果：', y_pre_rfc)\n",
    "\n",
    "print('训练集分数：', rfc.score(new_X_train, y_train))\n",
    "print('测试集分数：', rfc.score(new_X_test, y_test))\n",
    "# 混淆矩阵\n",
    "conf_mat = confusion_matrix(y_test, y_pre_rfc)\n",
    "plt.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "for (i, j), z in np.ndenumerate(conf_mat):\n",
    "    plt.text(j, i, '{0:d}'.format(z), ha='center', va='center')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "\n",
    "# 分类指标文本报告（精确率、召回率、F1值等）\n",
    "print('分类指标报告：')\n",
    "print(classification_report(y_test, y_pre_rfc))\n",
    "\n",
    "# 特征重要性\n",
    "print(rfc.feature_importances_)\n",
    "\n",
    "# 画图展示训练结果\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "f2 = ax.scatter(list(range(len(X_test))), y_pre_rfc, marker='o')\n",
    "f1 = ax.scatter(list(range(len(X_test))), y_test, marker='*')\n",
    "plt.legend(handles=[f1, f2], labels=['True', 'Prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_features_importances(feature_importances, feature_names):\n",
    "    plt.figure(figsize=(5, 20))\n",
    "    indices = np.argsort(feature_importances) # 下标排序\n",
    "    indices_flip = indices[::-1] # 倒序\n",
    "    names = []\n",
    "    for f in range(len(feature_names)):\n",
    "        names.append(feature_names[indices[f]])\n",
    "        print(\"%2d) %-*s %f\" % \\\n",
    "              (f + 1, 30, feature_names[indices_flip[f]], feature_importances[indices_flip[f]]))\n",
    "    pos = np.arange(indices.shape[0])\n",
    "    plt.barh(pos, feature_importances[indices], align=\"center\")\n",
    "    plt.ylim([pos[0] - 1, pos[-1] + 1])\n",
    "    plt.ylabel(\"排序\", fontname='SimSun', fontsize=10)\n",
    "    plt.xlabel(\"相对重要性\", fontname='SimSun', fontsize=10)\n",
    "    plt.yticks(pos, names, fontsize=5)\n",
    "    plt.xticks(fontsize=5)\n",
    "    xlabel = feature_importances[indices]\n",
    "    ylabel = pos\n",
    "    for x1, y1 in zip(xlabel, ylabel):\n",
    "        x1 = np.around(x1, decimals=3)\n",
    "        plt.text(x1 + 0.0005, y1 - 0.25, '%.3f' % x1, fontsize=5)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_features_importances(rfc.feature_importances_, x_label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc =  MLPClassifier(hidden_layer_sizes=(100, 50, 25), max_iter=1000,learning_rate_init=0.001)\n",
    "mlpc.fit(new_X_train, y_train)\n",
    "y_pre_rfc = mlpc.predict(new_X_test)\n",
    "\n",
    "print('正确标签：', y_test)\n",
    "print('预测结果：', y_pre_rfc)\n",
    "\n",
    "print('训练集分数：', rfc.score(new_X_train, y_train))\n",
    "print('测试集分数：', rfc.score(new_X_test, y_test))\n",
    "# 混淆矩阵\n",
    "conf_mat = confusion_matrix(y_test, y_pre_rfc)\n",
    "plt.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "for (i, j), z in np.ndenumerate(conf_mat):\n",
    "    plt.text(j, i, '{0:d}'.format(z), ha='center', va='center')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "\n",
    "# 分类指标文本报告（精确率、召回率、F1值等）\n",
    "print('分类指标报告：')\n",
    "print(classification_report(y_test, y_pre_rfc))\n",
    "\n",
    "\n",
    "# 画图展示训练结果\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "f2 = ax.scatter(list(range(len(X_test))), y_pre_rfc, marker='o')\n",
    "f1 = ax.scatter(list(range(len(X_test))), y_test, marker='*')\n",
    "plt.legend(handles=[f1, f2], labels=['True', 'Prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc = KNeighborsClassifier()\n",
    "knc.fit(new_X_train, y_train)\n",
    "y_pre_rfc = knc.predict(new_X_test)\n",
    "\n",
    "print('正确标签：', y_test)\n",
    "print('预测结果：', y_pre_rfc)\n",
    "\n",
    "print('训练集分数：', rfc.score(new_X_train, y_train))\n",
    "print('测试集分数：', rfc.score(new_X_test, y_test))\n",
    "# 混淆矩阵\n",
    "conf_mat = confusion_matrix(y_test, y_pre_rfc)\n",
    "plt.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "for (i, j), z in np.ndenumerate(conf_mat):\n",
    "    plt.text(j, i, '{0:d}'.format(z), ha='center', va='center')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "\n",
    "# 分类指标文本报告（精确率、召回率、F1值等）\n",
    "print('分类指标报告：')\n",
    "print(classification_report(y_test, y_pre_rfc))\n",
    "\n",
    "\n",
    "# 画图展示训练结果\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "f2 = ax.scatter(list(range(len(X_test))), y_pre_rfc, marker='o')\n",
    "f1 = ax.scatter(list(range(len(X_test))), y_test, marker='*')\n",
    "plt.legend(handles=[f1, f2], labels=['True', 'Prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stacking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AveragingModels(ClassifierMixin, BaseEstimator):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "\n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    #Now we do the predictions for cloned models and vote for result\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        res_len = predictions.shape[0]\n",
    "        pred_res = np.empty((res_len,), np.bool_)\n",
    "        for i in range(res_len):\n",
    "            counter = Counter(predictions[i].tolist())\n",
    "            pred_res[i] = counter.most_common(1)[0][0]\n",
    "        return pred_res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "stac = StackingClassifier(classifiers=(rfc, mlpc, knc), meta_classifier=lr)\n",
    "stac.fit(new_X_train, y_train)\n",
    "y_pre_rfc = stac.predict(new_X_test)\n",
    "print('正确标签：', y_test)\n",
    "print('预测结果：', y_pre_rfc)\n",
    "\n",
    "print('训练集分数：', rfc.score(new_X_train, y_train))\n",
    "print('测试集分数：', rfc.score(new_X_test, y_test))\n",
    "# 混淆矩阵\n",
    "conf_mat = confusion_matrix(y_test, y_pre_rfc)\n",
    "plt.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "for (i, j), z in np.ndenumerate(conf_mat):\n",
    "    plt.text(j, i, '{0:d}'.format(z), ha='center', va='center')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "\n",
    "# 分类指标文本报告（精确率、召回率、F1值等）\n",
    "print('分类指标报告：')\n",
    "print(classification_report(y_test, y_pre_rfc))\n",
    "\n",
    "\n",
    "# 画图展示训练结果\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "f2 = ax.scatter(list(range(len(X_test))), y_pre_rfc, marker='o')\n",
    "f1 = ax.scatter(list(range(len(X_test))), y_test, marker='*')\n",
    "plt.legend(handles=[f1, f2], labels=['True', 'Prediction'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 绘制ROC曲线"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 输出高清图像\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import platform\n",
    "## 图像显示中文的问题，需要判断系统是windows还是苹果的\n",
    "import matplotlib\n",
    "import platform\n",
    "sys_platform = platform.platform().lower()\n",
    "if \"windows\" in sys_platform:\n",
    "    font = {\n",
    "    \"family\": \"Microsoft YaHei\"\n",
    "    }\n",
    "    matplotlib.rc(\"font\", **font)\n",
    "else:\n",
    "    font = {\n",
    "    \"family\": \"Arial Unicode MS\"\n",
    "    }\n",
    "    matplotlib.rc(\"font\", **font)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# 可视化在验证集上的Roc曲线\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "plot_roc_curve(rfc, new_X_test, y_test, ax=ax)\n",
    "plot_roc_curve(mlpc, new_X_test, y_test, ax=ax)\n",
    "plot_roc_curve(knc, new_X_test, y_test, ax=ax)\n",
    "# stacking模型\n",
    "fpr,tpr, thresholds = roc_curve(y_test, stac.decision_function(new_X_test))\n",
    "stack_auc = roc_auc_score(y_test, stac.decision_function(new_X_test))\n",
    "plt.plot(fpr, tpr, label=\"Stacking(AUC={:.2f})\".format(stack_auc))\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"假正率\")\n",
    "plt.ylabel(\"真正率\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"ROC曲线\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 保存训练好的模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归问题"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso,Ridge, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "import xgboost as xgb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特征过程"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = [\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\", \"m7\", \"m8\", \"m9\", \"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\", \"k8\", \"k9\", \"c1\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\", \"c9\", \"sa1\", \"sa2\", \"sa3\", \"sa4\", \"sa5\", \"sa6\", \"sa7\", \"sa8\", \"sa9\", \"sa10\", \"sa11\", \"sa12\", \"sa13\", \"sa14\", \"sa15\", \"sa16\", \"sa17\", \"sa18\", \"sa19\", \"sa20\", \"sa21\", \"sa22\", \"sa23\", \"sa24\", \"sa25\", \"sa26\", \"sa27\", \"sa28\", \"sa29\", \"sa30\", \"sv1\", \"sv2\", \"sv3\", \"sv4\", \"sv5\", \"sv6\", \"sv7\", \"sv8\", \"sv9\", \"sv10\", \"sv11\", \"sv12\", \"sv13\", \"sv14\", \"sv15\", \"sv16\", \"sv17\", \"sv18\", \"sv19\", \"sv20\", \"sv21\", \"sv22\", \"sv23\", \"sv24\", \"sv25\", \"sv26\", \"sv27\", \"sv28\", \"sv29\", \"sv30\", \"sd1\", \"sd2\", \"sd3\", \"sd4\", \"sd5\", \"sd6\", \"sd7\", \"sd8\", \"sd9\", \"sd10\", \"sd11\", \"sd12\", \"sd13\", \"sd14\", \"sd15\", \"sd16\", \"sd17\", \"sd18\", \"sd19\", \"sd20\", \"sd21\", \"sd22\", \"sd23\", \"sd24\", \"sd25\", \"sd26\", \"sd27\", \"sd28\", \"sd29\", \"sd30\", \"sa_max\", \"sa_avg\", \"sv_max\", \"sv_avg\", \"sd_max\", \"sd_avg\", \"pga\", \"pgv\", \"pgd\", \"epa\", \"epv\", \"epd\", \"pa\", \"pv\", \"pd\", \"ic\"]\n",
    "y_label = [\"drift_max\", \"drift_avg\", \"a_max\", \"a_avg\", \"T_1\"]\n",
    "df_ok_origin = df[df.ok==True]\n",
    "df_ok = df_ok_origin.copy()\n",
    "df_ok.describe()\n",
    "X = df_ok.loc[:, x_label].values\n",
    "y = df_ok.loc[:, y_label].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ok = df_ok_origin.copy()\n",
    "# from scipy import stats\n",
    "# from scipy.stats import norm\n",
    "# import seaborn as sns\n",
    "# #Normal Distribution of Sales Price\n",
    "# mu, sigma = norm.fit(df_ok[yy_label])\n",
    "# print(\"Mu : {:.2f}\\nSigma : {:.2f}\".format(mu,sigma))\n",
    "#\n",
    "# #Visualization\n",
    "# sns.distplot(df_ok[yy_label],fit=norm)\n",
    "# plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\Sigma=$ {:.2f})'.format(mu,sigma)],loc = 'best')\n",
    "# plt.xlabel('SalePrice Distribution')\n",
    "# plt.ylabel('Frequency')\n",
    "#\n",
    "# fig = plt.figure()\n",
    "# res = stats.probplot(df_ok[yy_label],plot=plt)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ok[yy_label] = np.log(df_ok[yy_label])\n",
    "# # print(df_ok[yy_label])\n",
    "# #Normal Distribution of New Sales Price\n",
    "# mu, sigma = norm.fit(df_ok[yy_label])\n",
    "# print(\"Mu : {:.2f}\\nSigma : {:.2f}\".format(mu,sigma))\n",
    "#\n",
    "# #Visualization\n",
    "# sns.distplot(df_ok[yy_label],fit=norm)\n",
    "# plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\Sigma=$ {:.2f})'.format(mu,sigma)],loc = 'best')\n",
    "# plt.xlabel('SalePrice Distribution')\n",
    "# plt.ylabel('Frequency')\n",
    "# fig = plt.figure()\n",
    "# res = stats.probplot(df_ok[yy_label], plot=plt)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "y_train_theta_max = y_train[:, 0]\n",
    "y_test_theta_max = y_test[:, 0]\n",
    "y_train_theta_avg = y_train[:, 1]\n",
    "y_test_theta_avg = y_test[:, 1]\n",
    "y_train_a_max = y_train[:, 2]\n",
    "y_test_a_max = y_test[:, 2]\n",
    "y_train_a_avg = y_train[:, 3]\n",
    "y_test_a_avg = y_test[:, 3]\n",
    "y_train_T1 = y_train[:, 4]\n",
    "y_test_T1 = y_test[:, 4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征标准化，采用最大最小值标准化，转化后的值范围（0,1）\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "new_X_train = X_train\n",
    "new_X_test = X_test\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# normalizer = Normalizer(copy=True, norm='l2').fit(new_X_train)\n",
    "# new_X_train = normalizer.transform(new_X_train)\n",
    "# new_X_test = normalizer.transform(new_X_test)\n",
    "ss = StandardScaler().fit(new_X_train)\n",
    "new_X_train = ss.transform(new_X_train)\n",
    "new_X_test = ss.transform(new_X_test)\n",
    "\n",
    "new_X_T1_train = new_X_train[:, 0: 27]\n",
    "new_X_T1_test = new_X_test[:, 0: 27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "\n",
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model, X_train, y_train):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_regression_results(ax, y_true, y_pred, title, scores, elapsed_time):\n",
    "    \"\"\"预测目标与真实目标的散点图。\"\"\"\n",
    "    ax.plot([y_true.min(), y_true.max()],\n",
    "            [y_true.min(), y_true.max()],'--r', linewidth=2)\n",
    "    ax.scatter(y_true, y_pred, alpha=0.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    ax.spines['bottom'].set_position(('outward', 10))\n",
    "    ax.set_xlim([y_true.min(), y_true.max()])\n",
    "    ax.set_ylim([y_true.min(), y_true.max()])\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    extra = plt.Rectangle((0, 0), 0, 0, fc=\"w\", fill=False,\n",
    "                          edgecolor='none', linewidth=0)\n",
    "    ax.legend([extra], [scores], loc='upper left')\n",
    "    title = title + '\\n Evaluation in {:.2f} seconds'.format(elapsed_time)\n",
    "    ax.set_title(title)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 基础模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* RandomForest Regressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_theta_max = RandomForestRegressor()\n",
    "rfr_theta_avg = RandomForestRegressor()\n",
    "rfr_a_max = RandomForestRegressor()\n",
    "rfr_a_avg = RandomForestRegressor()\n",
    "# model_rf.fit(new_X_train,y_train)\n",
    "# y_pred_rf = model_rf.predict(new_X_train)\n",
    "# score_rf = np.sqrt(mean_squared_error(y_train, y_pred_rf))\n",
    "# print(\"RandomForest Score(On Training DataSet)  :\",score_rf)\n",
    "#\n",
    "# y_pred_rf_test = model_rf.predict(new_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "* LASSO Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lasso_theta_max = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "lasso_theta_avg = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "lasso_a_max = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "lasso_a_avg = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Elastic Net Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ENet_theta_max = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "ENet_theta_avg = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "ENet_a_max = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "ENet_a_avg = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Kernel Ridge Regression :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KRR_theta_max = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "KRR_theta_avg = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "KRR_a_max = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "KRR_a_avg = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Gradient Boosting Regression :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GBoost_theta_max = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10,\n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost_theta_avg = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10,\n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost_a_max = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10,\n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost_a_avg = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10,\n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost_T1 = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                         max_depth=4, max_features='sqrt',\n",
    "                                         min_samples_leaf=15, min_samples_split=10,\n",
    "                                         loss='huber', random_state=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* XGBoost :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_xgb_theta_max = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468,\n",
    "                             learning_rate=0.05, max_depth=3,\n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_xgb_theta_avg = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468,\n",
    "                             learning_rate=0.05, max_depth=3,\n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_xgb_a_max = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468,\n",
    "                             learning_rate=0.05, max_depth=3,\n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_xgb_a_avg = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468,\n",
    "                             learning_rate=0.05, max_depth=3,\n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base models scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = rmsle_cv(rfr_theta_max, new_X_train, y_train_theta_max)\n",
    "print(\"\\nRfr_theta_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(rfr_theta_avg, new_X_train, y_train_theta_avg)\n",
    "print(\"\\nRfr_theta_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(rfr_a_max, new_X_train, y_train_a_max)\n",
    "print(\"\\nRfr_a_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(rfr_a_avg, new_X_train, y_train_a_avg)\n",
    "print(\"\\nRfr_a_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = rmsle_cv(lasso_theta_max, new_X_train, y_train_theta_max)\n",
    "print(\"\\nLasso_theta_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(lasso_theta_avg, new_X_train, y_train_theta_avg)\n",
    "print(\"\\nLasso_theta_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(lasso_a_max, new_X_train, y_train_a_max)\n",
    "print(\"\\nLasso_a_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(lasso_a_avg, new_X_train, y_train_a_avg)\n",
    "print(\"\\nLasso_a_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = rmsle_cv(ENet_theta_max, new_X_train, y_train_theta_max)\n",
    "print(\"\\nENet_theta_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(ENet_theta_avg, new_X_train, y_train_theta_avg)\n",
    "print(\"\\nENet_theta_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(ENet_a_max, new_X_train, y_train_a_max)\n",
    "print(\"\\nENet_a_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(ENet_a_avg, new_X_train, y_train_a_avg)\n",
    "print(\"\\nENet_a_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = rmsle_cv(KRR_theta_max, new_X_train, y_train_theta_max)\n",
    "print(\"\\nKernel Ridge_theta_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(KRR_theta_avg, new_X_train, y_train_theta_avg)\n",
    "print(\"\\nKernel Ridge_theta_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(KRR_a_max, new_X_train, y_train_a_max)\n",
    "print(\"\\nKernel Ridge_a_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(KRR_a_avg, new_X_train, y_train_a_avg)\n",
    "print(\"\\nKernel Ridge_a_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = rmsle_cv(GBoost_theta_max, new_X_train, y_train_theta_max)\n",
    "print(\"\\nGradient Boosting_theta_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(GBoost_theta_avg, new_X_train, y_train_theta_avg)\n",
    "print(\"\\nGradient Boosting_theta_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(GBoost_a_max, new_X_train, y_train_a_max)\n",
    "print(\"\\nGradient Boosting_a_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(GBoost_a_avg, new_X_train, y_train_a_avg)\n",
    "print(\"\\nGradient Boosting_a_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = rmsle_cv(model_xgb_theta_max, new_X_train, y_train_theta_max)\n",
    "print(\"\\nXgboost_theta_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "score = rmsle_cv(model_xgb_theta_avg, new_X_train, y_train_theta_avg)\n",
    "print(\"\\nXgboost_theta_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(model_xgb_a_max, new_X_train, y_train_a_max)\n",
    "print(\"\\nXgboost_a_max score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(model_xgb_a_avg, new_X_train, y_train_a_avg)\n",
    "print(\"\\nXgboost_a_avg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stacked_averaged_models_theta_max = StackingRegressor(regressors = (ENet_theta_max, rfr_theta_max, KRR_theta_max),\n",
    "                                                 meta_regressor = lasso_theta_max)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models_theta_max, new_X_train, y_train_theta_max)\n",
    "print(\"Stacking Averaged models theta_max score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "\n",
    "stacked_averaged_models_theta_avg = StackingRegressor(regressors = (ENet_theta_avg, rfr_theta_avg, KRR_theta_avg),\n",
    "                                                 meta_regressor = lasso_theta_avg)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models_theta_avg, new_X_train, y_train_theta_avg)\n",
    "print(\"Stacking Averaged models theta_avg score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "\n",
    "stacked_averaged_models_a_max = StackingRegressor(regressors = (ENet_a_max, rfr_a_max, KRR_a_max),\n",
    "                                                 meta_regressor = lasso_a_max)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models_a_max, new_X_train, y_train_a_max)\n",
    "print(\"Stacking Averaged models a_max score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "\n",
    "stacked_averaged_models_a_avg = StackingRegressor(regressors = (ENet_a_avg, rfr_a_avg, KRR_a_avg),\n",
    "                                                 meta_regressor = lasso_a_avg)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models_a_avg, new_X_train, y_train_a_avg)\n",
    "print(\"Stacking Averaged models a_avg score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_regression_results(ax, y_true, y_pred, title, scores):\n",
    "    \"\"\"预测目标与真实目标的散点图。\"\"\"\n",
    "    ax.plot([y_true.min(), y_true.max()],\n",
    "            [y_true.min(), y_true.max()],'--r', linewidth=2)\n",
    "    ax.scatter(y_true, y_pred, alpha=0.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    ax.spines['bottom'].set_position(('outward', 10))\n",
    "    ax.set_xlim([y_true.min(), y_true.max()])\n",
    "    ax.set_ylim([y_true.min(), y_true.max()])\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    extra = plt.Rectangle((0, 0), 0, 0, fc=\"w\", fill=False,\n",
    "                          edgecolor='none', linewidth=0)\n",
    "    ax.legend([extra], [scores], loc='upper left')\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_model_theta_max = GBoost_theta_max\n",
    "select_model_theta_avg = GBoost_theta_avg\n",
    "select_model_a_max = GBoost_a_max\n",
    "select_model_a_avg = GBoost_a_avg\n",
    "select_model_T1 = GBoost_T1\n",
    "\n",
    "select_model_theta_max.fit(new_X_train, y_train_theta_max)\n",
    "select_model_theta_avg.fit(new_X_train, y_train_theta_avg)\n",
    "select_model_a_max.fit(new_X_train, y_train_a_max)\n",
    "select_model_a_avg.fit(new_X_train, y_train_a_avg)\n",
    "select_model_T1.fit(new_X_T1_train, y_train_T1)\n",
    "\n",
    "train_pred_theta_max = select_model_theta_max.predict(new_X_train)\n",
    "pred_theta_max = select_model_theta_max.predict(new_X_test)\n",
    "print(rmsle(y_train_theta_max, train_pred_theta_max))\n",
    "\n",
    "train_pred_theta_avg = select_model_theta_avg.predict(new_X_train)\n",
    "pred_theta_avg = select_model_theta_avg.predict(new_X_test)\n",
    "print(rmsle(y_train_theta_avg, train_pred_theta_avg))\n",
    "\n",
    "train_pred_a_max = select_model_a_max.predict(new_X_train)\n",
    "pred_a_max = select_model_a_max.predict(new_X_test)\n",
    "print(rmsle(y_train_a_max, train_pred_a_max))\n",
    "\n",
    "train_pred_a_avg = select_model_a_avg.predict(new_X_train)\n",
    "pred_a_avg = select_model_a_avg.predict(new_X_test)\n",
    "print(rmsle(y_train_a_avg, train_pred_a_avg))\n",
    "\n",
    "train_pred_T1 = select_model_T1.predict(new_X_T1_train)\n",
    "pred_T1 = select_model_T1.predict(new_X_T1_test)\n",
    "print(rmsle(y_train_T1, train_pred_T1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "r2_theta_max = r2_score(y_test_theta_max, pred_theta_max)\n",
    "mse_theta_max = mean_squared_error(y_test_theta_max, pred_theta_max)\n",
    "mape_theta_max = mean_absolute_percentage_error(y_test_theta_max, pred_theta_max)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "        ax, y_test_theta_max, pred_theta_max,\n",
    "        \"Stacking Regressor\",\n",
    "        (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "        .format(r2_theta_max, mse_theta_max, mape_theta_max))\n",
    "\n",
    "\n",
    "r2_theta_avg = r2_score(y_test_theta_avg, pred_theta_avg)\n",
    "mse_theta_avg = mean_squared_error(y_test_theta_avg, pred_theta_avg)\n",
    "mape_theta_avg = mean_absolute_percentage_error(y_test_theta_avg, pred_theta_avg)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "        ax, y_test_theta_avg, pred_theta_avg,\n",
    "        \"Stacking Regressor\",\n",
    "        (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "        .format(r2_theta_avg, mse_theta_avg, mape_theta_avg))\n",
    "\n",
    "\n",
    "r2_a_max = r2_score(y_test_a_max, pred_a_max)\n",
    "mse_a_max = mean_squared_error(y_test_a_max, pred_a_max)\n",
    "mape_a_max = mean_absolute_percentage_error(y_test_a_max, pred_a_max)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "        ax, y_test_a_max, pred_a_max,\n",
    "        \"Stacking Regressor\",\n",
    "        (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "        .format(r2_a_max, mse_a_max, mape_a_max))\n",
    "\n",
    "\n",
    "r2_a_avg = r2_score(y_test_a_avg, pred_a_avg)\n",
    "mse_a_avg = mean_squared_error(y_test_a_avg, pred_a_avg)\n",
    "mape_a_avg = mean_absolute_percentage_error(y_test_a_avg, pred_a_avg)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "        ax, y_test_a_avg, pred_a_avg,\n",
    "        \"Stacking Regressor\",\n",
    "        (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "        .format(r2_a_avg, mse_a_avg, mape_a_avg))\n",
    "\n",
    "\n",
    "r2_T1 = r2_score(y_test_T1, pred_T1)\n",
    "mse_T1 = mean_squared_error(y_test_T1, pred_T1)\n",
    "mape_T1 = mean_absolute_percentage_error(y_test_T1, pred_T1)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "        ax, y_test_T1, pred_T1,\n",
    "        \"Stacking Regressor\",\n",
    "        (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "        .format(r2_T1, mse_T1, mape_T1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
