{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from control import lqr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os, re\n",
    "import pandas as pd\n",
    "from matplotlib import font_manager  #matplotlib中 中文设置模块"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 输出高清图像\n",
    "% config InlineBackend.figure_format = 'retina'\n",
    "% matplotlib inline\n",
    "import platform\n",
    "# 图像显示中文的问题，需要判断系统是windows还是苹果的\n",
    "import matplotlib\n",
    "import platform\n",
    "\n",
    "sys_platform = platform.platform().lower()\n",
    "if \"windows\" in sys_platform:\n",
    "    font = {\n",
    "        \"family\": \"Times New Roman\"\n",
    "    }\n",
    "    matplotlib.rc(\"font\", **font)\n",
    "else:\n",
    "    font = {\n",
    "        \"family\": \"Arial Unicode MS\"\n",
    "    }\n",
    "    matplotlib.rc(\"font\", **font)\n",
    "rc = {\"mathtext.fontset\": \"stix\", }\n",
    "\n",
    "plt.rcParams.update(rc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('./data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/opensees_design_res.csv')\n",
    "df.info()\n",
    "df['ok'] = True\n",
    "df.loc[df[\"drift_max\"] > 1 / 200, ['ok']] = False\n",
    "df.loc[df[\"a_max\"] > 0.35 * 9.8, ['ok']] = False\n",
    "df.sample(3)\n",
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"ok\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 特征排序\n",
    "def plot_features_importances(feature_importances, feature_names):\n",
    "    \"\"\"\n",
    "    特征重要性排序，选出占重要性排序前90%的特征\n",
    "    :param feature_importances:  特征重要性\n",
    "    :param feature_names: 特征名称\n",
    "    :return: 主要的特征\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(5, 20))\n",
    "    indices = np.argsort(feature_importances)  # 下标排序\n",
    "    indices_flip = indices[::-1]  # 倒序\n",
    "    names = []\n",
    "    for f in range(len(feature_names)):\n",
    "        names.append(feature_names[indices[f]])\n",
    "        print(\"%2d) %-*s %f\" % (f + 1, 30, feature_names[indices_flip[f]], feature_importances[indices_flip[f]]))\n",
    "\n",
    "    # 取前90%重要性的数据\n",
    "    sum_importances = 0\n",
    "    threshold = 0\n",
    "    for i in range(len(feature_importances)):\n",
    "        sum_importances += feature_importances[indices[i]]\n",
    "        if sum_importances >= 0.05:\n",
    "            threshold = i\n",
    "            break\n",
    "\n",
    "    pos = np.arange(indices.shape[0])\n",
    "    plt.barh(pos[0:threshold], feature_importances[indices[0:threshold]], align=\"center\")\n",
    "    plt.barh(pos[threshold:], feature_importances[indices[threshold:]], align=\"center\", color=\"red\")\n",
    "    plt.ylim([pos[0] - 1, pos[-1] + 1])\n",
    "    plt.ylabel(\"排序\", fontname='SimSun', fontsize=10)\n",
    "    plt.xlabel(\"相对重要性\", fontname='SimSun', fontsize=10)\n",
    "    plt.yticks(pos, names, fontsize=5)\n",
    "    plt.xticks(fontsize=5)\n",
    "    xlabel = feature_importances[indices]\n",
    "    ylabel = pos\n",
    "    for x1, y1 in zip(xlabel, ylabel):\n",
    "        x1 = np.around(x1, decimals=3)\n",
    "        plt.text(x1 + 0.0005, y1 - 0.25, '%.3f' % x1, fontsize=5)\n",
    "    plt.show()\n",
    "    return names[threshold:][::-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Libs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 利用GridSearchCV选择最优参数\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特征过程"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉id,site_name,miu,zeta,kappa,gamma,alpha,\n",
    "x_label = [\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\", \"m7\", \"m8\", \"m9\", \"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\", \"k8\", \"k9\",\n",
    "           \"c1\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\", \"c9\", \"sa1\", \"sa2\", \"sa3\", \"sa4\", \"sa5\", \"sa6\", \"sa7\", \"sa8\",\n",
    "           \"sa9\", \"sa10\", \"sa11\", \"sa12\", \"sa13\", \"sa14\", \"sa15\", \"sa16\", \"sa17\", \"sa18\", \"sa19\", \"sa20\", \"sa21\",\n",
    "           \"sa22\", \"sa23\", \"sa24\", \"sa25\", \"sa26\", \"sa27\", \"sa28\", \"sa29\", \"sa30\", \"sv1\", \"sv2\", \"sv3\", \"sv4\", \"sv5\",\n",
    "           \"sv6\", \"sv7\", \"sv8\", \"sv9\", \"sv10\", \"sv11\", \"sv12\", \"sv13\", \"sv14\", \"sv15\", \"sv16\", \"sv17\", \"sv18\", \"sv19\",\n",
    "           \"sv20\", \"sv21\", \"sv22\", \"sv23\", \"sv24\", \"sv25\", \"sv26\", \"sv27\", \"sv28\", \"sv29\", \"sv30\", \"sd1\", \"sd2\", \"sd3\",\n",
    "           \"sd4\", \"sd5\", \"sd6\", \"sd7\", \"sd8\", \"sd9\", \"sd10\", \"sd11\", \"sd12\", \"sd13\", \"sd14\", \"sd15\", \"sd16\", \"sd17\",\n",
    "           \"sd18\", \"sd19\", \"sd20\", \"sd21\", \"sd22\", \"sd23\", \"sd24\", \"sd25\", \"sd26\", \"sd27\", \"sd28\", \"sd29\", \"sd30\",\n",
    "           \"sa_max\", \"sa_avg\", \"sv_max\", \"sv_avg\", \"sd_max\", \"sd_avg\", \"pga\", \"pgv\", \"pgd\", \"epa\", \"epv\", \"epd\", \"pa\",\n",
    "           \"pv\", \"pd\", \"ic\"]\n",
    "y_label = [\"ok\"]\n",
    "X = df.loc[:, x_label].values\n",
    "y = df.loc[:, y_label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2)\n",
    "# y_test = y_test.reshape([-1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle_index = np.random.permutation(934)\n",
    "# X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = X_train\n",
    "new_X_test = X_test\n",
    "\n",
    "# normalizer = Normalizer(copy=True, norm='l2').fit(new_X_train)\n",
    "ss = StandardScaler().fit(new_X_train)\n",
    "new_X_train = ss.transform(new_X_train)\n",
    "new_X_test = ss.transform(new_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 贝叶斯优化\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "param_grid = {'max_depth': np.linspace(start=10, stop=500, num=50, dtype=int),\n",
    "              'n_estimators': np.linspace(start=50, stop=3000, num=60, dtype=int),\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'min_samples_leaf': np.array([2, 5, 10, 15], dtype=int),\n",
    "              'min_samples_split': np.array([2, 5, 10, 15], dtype=int),\n",
    "              'random_state': [3]}\n",
    "\n",
    "opt = BayesSearchCV(rfc, param_grid, n_iter=50, n_jobs=3, cv=3)\n",
    "\n",
    "opt.fit(new_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(opt.best_params_)\n",
    "best_params = opt.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=best_params[\"n_estimators\"],\n",
    "                             criterion=best_params['criterion'],\n",
    "                             max_depth=best_params[\"max_depth\"], min_samples_split=best_params[\"min_samples_split\"],\n",
    "                             min_samples_leaf=best_params[\"min_samples_leaf\"], random_state=best_params[\"random_state\"])\n",
    "rfc.fit(new_X_train, y_train)\n",
    "y_pre_rfc = rfc.predict(new_X_test)\n",
    "\n",
    "print('正确标签：', y_test)\n",
    "print('预测结果：', y_pre_rfc)\n",
    "\n",
    "print('训练集分数：', rfc.score(new_X_train, y_train))\n",
    "print('测试集分数：', rfc.score(new_X_test, y_test))\n",
    "# 混淆矩阵\n",
    "conf_mat = confusion_matrix(y_test, y_pre_rfc)\n",
    "plt.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "for (i, j), z in np.ndenumerate(conf_mat):\n",
    "    plt.text(j, i, '{0:d}'.format(z), ha='center', va='center')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "# 分类指标文本报告（精确率、召回率、F1值等）\n",
    "print('分类指标报告：')\n",
    "print(classification_report(y_test, y_pre_rfc))\n",
    "\n",
    "# 特征重要性\n",
    "print(rfc.feature_importances_)\n",
    "\n",
    "# 画图展示训练结果\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "f2 = ax.scatter(list(range(len(X_test))), y_pre_rfc, marker='o')\n",
    "f1 = ax.scatter(list(range(len(X_test))), y_test, marker='*')\n",
    "plt.legend(handles=[f1, f2], labels=['True', 'Prediction'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main_features = plot_features_importances(rfc.feature_importances_, x_label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 使用主特征\n",
    "X_main = df.loc[:, main_features].values\n",
    "X_main_train, X_main_test, y_train, y_test = train_test_split(X_main, y, test_size=0.1, random_state=2)\n",
    "print(X_main_train.shape, X_main_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "new_X_main_train = X_main_train\n",
    "new_X_main_test = X_main_test\n",
    "\n",
    "ss_main = StandardScaler().fit(new_X_main_train)\n",
    "new_X_main_train = ss_main.transform(new_X_main_train)\n",
    "new_X_main_test = ss_main.transform(new_X_main_test)\n",
    "new_X_main_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=best_params[\"n_estimators\"],\n",
    "                             criterion=best_params['criterion'],\n",
    "                             max_depth=best_params[\"max_depth\"], min_samples_split=best_params[\"min_samples_split\"],\n",
    "                             min_samples_leaf=best_params[\"min_samples_leaf\"], random_state=best_params[\"random_state\"])\n",
    "rfc.fit(new_X_main_train, y_train)\n",
    "y_pre_rfc = rfc.predict(new_X_main_test)\n",
    "\n",
    "print('正确标签：', y_test)\n",
    "print('预测结果：', y_pre_rfc)\n",
    "\n",
    "print('训练集分数：', rfc.score(new_X_main_train, y_train))\n",
    "print('测试集分数：', rfc.score(new_X_main_test, y_test))\n",
    "# 混淆矩阵\n",
    "conf_mat = confusion_matrix(y_test, y_pre_rfc)\n",
    "plt.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "for (i, j), z in np.ndenumerate(conf_mat):\n",
    "    plt.text(j, i, '{0:d}'.format(z), ha='center', va='center')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "# 分类指标文本报告（精确率、召回率、F1值等）\n",
    "print('分类指标报告：')\n",
    "print(classification_report(y_test, y_pre_rfc))\n",
    "\n",
    "# 特征重要性\n",
    "print(rfc.feature_importances_)\n",
    "\n",
    "# 画图展示训练结果\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "f2 = ax.scatter(list(range(len(X_test))), y_pre_rfc, marker='o')\n",
    "f1 = ax.scatter(list(range(len(X_test))), y_test, marker='*')\n",
    "plt.legend(handles=[f1, f2], labels=['True', 'Prediction'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 贝叶斯优化\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# 贝叶斯优化\n",
    "xgBoostC = XGBClassifier()\n",
    "random_state = 3\n",
    "\n",
    "param_grid = {'learning_rate': np.array([0.01, 0.015, 0.025, 0.05, 0.1], dtype=float),\n",
    "              'gamma': np.array([0, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9, 1], dtype=float),\n",
    "              \"reg_alpha\": np.array([0, 0.01, 0.1, 1], dtype=float),\n",
    "              \"reg_lambda\": np.array([0, 0.1, 0.5, 1], dtype=float),\n",
    "              \"min_child_weight\": np.array([1, 3, 5, 7], dtype=int),\n",
    "              \"colsample_bytree\": np.array([0.5, 0.6, 0.7, 0.8, 0.9, 1], dtype=float),\n",
    "              'subsample': np.array([0.5, 0.6, 0.7, 0.8, 0.9, 1], dtype=float),\n",
    "              'max_depth': np.array([3, 5, 8, 15, 25, 30], dtype=int),\n",
    "              'n_estimators': np.linspace(start=50, stop=3000, num=60, dtype=int),\n",
    "              'random_state': [random_state]}\n",
    "\n",
    "opt = BayesSearchCV(xgBoostC, param_grid, n_iter=50, n_jobs=3, cv=3)\n",
    "\n",
    "opt.fit(new_X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(opt.best_params_)\n",
    "best_params = opt.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgBoostC = XGBClassifier(n_estimators=best_params[\"n_estimators\"],\n",
    "                         colsample_bytree=best_params['colsample_bytree'],\n",
    "                         max_depth=best_params[\"max_depth\"],\n",
    "                         learning_rate=best_params[\"learning_rate\"],\n",
    "                         gamma=best_params[\"gamma\"],\n",
    "                         min_child_weight=best_params[\"min_child_weight\"],\n",
    "                         reg_alpha=best_params[\"reg_alpha\"],\n",
    "                         reg_lambda=best_params[\"reg_lambda\"],\n",
    "                         subsample=best_params[\"subsample\"],\n",
    "                         random_state=best_params[\"random_state\"])\n",
    "xgBoostC.fit(new_X_train, y_train)\n",
    "y_pre_xgBoostC = xgBoostC.predict(new_X_test)\n",
    "\n",
    "print('正确标签：', y_test)\n",
    "print('预测结果：', y_pre_xgBoostC)\n",
    "\n",
    "print('训练集分数：', xgBoostC.score(new_X_train, y_train))\n",
    "print('测试集分数：', xgBoostC.score(new_X_test, y_test))\n",
    "# 混淆矩阵\n",
    "conf_mat = confusion_matrix(y_test, y_pre_xgBoostC)\n",
    "plt.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "for (i, j), z in np.ndenumerate(conf_mat):\n",
    "    plt.text(j, i, '{0:d}'.format(z), ha='center', va='center')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "# 分类指标文本报告（精确率、召回率、F1值等）\n",
    "print('分类指标报告：')\n",
    "print(classification_report(y_test, y_pre_xgBoostC))\n",
    "\n",
    "# 特征重要性\n",
    "print(xgBoostC.feature_importances_)\n",
    "\n",
    "# 画图展示训练结果\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "f2 = ax.scatter(list(range(len(X_test))), y_pre_xgBoostC, marker='o')\n",
    "f1 = ax.scatter(list(range(len(X_test))), y_test, marker='*')\n",
    "plt.legend(handles=[f1, f2], labels=['True', 'Prediction'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main_features = plot_features_importances(xgBoostC.feature_importances_, x_label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 使用主特征\n",
    "X_main = df.loc[:, main_features].values\n",
    "X_main_train, X_main_test, y_train, y_test = train_test_split(X_main, y, test_size=0.1, random_state=2)\n",
    "print(X_main_train.shape, X_main_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "new_X_main_train = X_main\n",
    "new_X_main_test = X_main_train\n",
    "\n",
    "ss_main = StandardScaler().fit(new_X_main_train)\n",
    "new_X_main_train = ss_main.transform(new_X_main_train)\n",
    "new_X_main_test = ss_main.transform(new_X_main_test)\n",
    "new_X_main_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgBoostC = XGBClassifier(n_estimators=best_params[\"n_estimators\"],\n",
    "                         colsample_bytree=best_params['colsample_bytree'],\n",
    "                         max_depth=best_params[\"max_depth\"],\n",
    "                         learning_rate=best_params[\"learning_rate\"],\n",
    "                         gamma=best_params[\"gamma\"],\n",
    "                         min_child_weight=best_params[\"min_child_weight\"],\n",
    "                         reg_alpha=best_params[\"reg_alpha\"],\n",
    "                         reg_lambda=best_params[\"reg_lambda\"],\n",
    "                         subsample=best_params[\"subsample\"],\n",
    "                         random_state=best_params[\"random_state\"])\n",
    "xgBoostC.fit(new_X_main_train, y_train)\n",
    "y_pre_xgBoostC = xgBoostC.predict(new_X_main_test)\n",
    "\n",
    "print('正确标签：', y_test)\n",
    "print('预测结果：', y_pre_xgBoostC)\n",
    "\n",
    "print('训练集分数：', xgBoostC.score(new_X_main_train, y_train))\n",
    "print('测试集分数：', xgBoostC.score(new_X_main_test, y_test))\n",
    "# 混淆矩阵\n",
    "conf_mat = confusion_matrix(y_test, y_pre_xgBoostC)\n",
    "plt.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "for (i, j), z in np.ndenumerate(conf_mat):\n",
    "    plt.text(j, i, '{0:d}'.format(z), ha='center', va='center')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "print('混淆矩阵：')\n",
    "print(conf_mat)\n",
    "\n",
    "# 分类指标文本报告（精确率、召回率、F1值等）\n",
    "print('分类指标报告：')\n",
    "print(classification_report(y_test, y_pre_xgBoostC))\n",
    "\n",
    "# 特征重要性\n",
    "print(xgBoostC.feature_importances_)\n",
    "\n",
    "# 画图展示训练结果\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "f2 = ax.scatter(list(range(len(X_test))), y_pre_xgBoostC, marker='o')\n",
    "f1 = ax.scatter(list(range(len(X_test))), y_test, marker='*')\n",
    "plt.legend(handles=[f1, f2], labels=['True', 'Prediction'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 绘制ROC曲线"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 输出高清图像\n",
    "% config InlineBackend.figure_format = 'retina'\n",
    "% matplotlib inline\n",
    "import platform\n",
    "## 图像显示中文的问题，需要判断系统是windows还是苹果的\n",
    "import matplotlib\n",
    "import platform\n",
    "\n",
    "sys_platform = platform.platform().lower()\n",
    "if \"windows\" in sys_platform:\n",
    "    font = {\n",
    "        \"family\": \"Microsoft YaHei\"\n",
    "    }\n",
    "    matplotlib.rc(\"font\", **font)\n",
    "else:\n",
    "    font = {\n",
    "        \"family\": \"Arial Unicode MS\"\n",
    "    }\n",
    "    matplotlib.rc(\"font\", **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# 可视化在验证集上的Roc曲线\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_roc_curve(rfc, new_X_test, y_test, ax=ax)\n",
    "plot_roc_curve(xgBoostC, new_X_test, y_test, ax=ax)\n",
    "# plot_roc_curve(knc, new_X_test, y_test, ax=ax)\n",
    "# stacking模型\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, stac.decision_function(new_X_test))\n",
    "# stack_auc = roc_auc_score(y_test, stac.decision_function(new_X_test))\n",
    "# plt.plot(fpr, tpr, label=\"Stacking(AUC={:.2f})\".format(stack_auc))\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"假正率\", fontname='SimSun', fontsize=10)\n",
    "plt.ylabel(\"真正率\", fontname='SimSun', fontsize=10)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "# plt.title(\"ROC曲线\", fontname='SimSun', fontsize=10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 保存训练好的模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归问题"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from xgboost import XGBRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特征过程"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = [\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\", \"m7\", \"m8\", \"m9\", \"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\", \"k8\", \"k9\",\n",
    "           \"c1\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\", \"c9\", \"sa1\", \"sa2\", \"sa3\", \"sa4\", \"sa5\", \"sa6\", \"sa7\", \"sa8\",\n",
    "           \"sa9\", \"sa10\", \"sa11\", \"sa12\", \"sa13\", \"sa14\", \"sa15\", \"sa16\", \"sa17\", \"sa18\", \"sa19\", \"sa20\", \"sa21\",\n",
    "           \"sa22\", \"sa23\", \"sa24\", \"sa25\", \"sa26\", \"sa27\", \"sa28\", \"sa29\", \"sa30\", \"sv1\", \"sv2\", \"sv3\", \"sv4\", \"sv5\",\n",
    "           \"sv6\", \"sv7\", \"sv8\", \"sv9\", \"sv10\", \"sv11\", \"sv12\", \"sv13\", \"sv14\", \"sv15\", \"sv16\", \"sv17\", \"sv18\", \"sv19\",\n",
    "           \"sv20\", \"sv21\", \"sv22\", \"sv23\", \"sv24\", \"sv25\", \"sv26\", \"sv27\", \"sv28\", \"sv29\", \"sv30\", \"sd1\", \"sd2\", \"sd3\",\n",
    "           \"sd4\", \"sd5\", \"sd6\", \"sd7\", \"sd8\", \"sd9\", \"sd10\", \"sd11\", \"sd12\", \"sd13\", \"sd14\", \"sd15\", \"sd16\", \"sd17\",\n",
    "           \"sd18\", \"sd19\", \"sd20\", \"sd21\", \"sd22\", \"sd23\", \"sd24\", \"sd25\", \"sd26\", \"sd27\", \"sd28\", \"sd29\", \"sd30\",\n",
    "           \"sa_max\", \"sa_avg\", \"sv_max\", \"sv_avg\", \"sd_max\", \"sd_avg\", \"pga\", \"pgv\", \"pgd\", \"epa\", \"epv\", \"epd\", \"pa\",\n",
    "           \"pv\", \"pd\", \"ic\"]\n",
    "\n",
    "y_label = [\"drift_max\", \"drift_avg\", \"a_max\", \"a_avg\", \"T_1\"]\n",
    "\n",
    "df_ok_origin = df[df.ok == True]\n",
    "df_ok = df_ok_origin.copy()\n",
    "df_ok.describe()\n",
    "X = df_ok.loc[:, x_label].values\n",
    "y = df_ok.loc[:, y_label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "y_train_theta_max = y_train[:, 0]\n",
    "y_test_theta_max = y_test[:, 0]\n",
    "y_train_theta_avg = y_train[:, 1]\n",
    "y_test_theta_avg = y_test[:, 1]\n",
    "y_train_a_max = y_train[:, 2]\n",
    "y_test_a_max = y_test[:, 2]\n",
    "y_train_a_avg = y_train[:, 3]\n",
    "y_test_a_avg = y_test[:, 3]\n",
    "y_train_T1 = y_train[:, 4]\n",
    "y_test_T1 = y_test[:, 4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征标准化，采用最大最小值标准化，转化后的值范围（0,1）\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "new_X_train = X_train\n",
    "new_X_test = X_test\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# normalizer = Normalizer(copy=True, norm='l2').fit(new_X_train)\n",
    "# new_X_train = normalizer.transform(new_X_train)\n",
    "# new_X_test = normalizer.transform(new_X_test)\n",
    "ss = StandardScaler().fit(new_X_train)\n",
    "new_X_train = ss.transform(new_X_train)\n",
    "new_X_test = ss.transform(new_X_test)\n",
    "\n",
    "new_X_T1_train = new_X_train[:, 0: 27]\n",
    "new_X_T1_test = new_X_test[:, 0: 27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_regression_results(ax, y_true, y_pred, title, scores):\n",
    "    \"\"\"预测目标与真实目标的散点图。\"\"\"\n",
    "    ax.plot([y_true.min(), y_true.max()],\n",
    "            [y_true.min(), y_true.max()], '--r', linewidth=2)\n",
    "    ax.scatter(y_true, y_pred, alpha=0.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    ax.spines['bottom'].set_position(('outward', 10))\n",
    "    ax.set_xlim([y_true.min(), y_true.max()])\n",
    "    ax.set_ylim([y_true.min(), y_true.max()])\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    extra = plt.Rectangle((0, 0), 0, 0, fc=\"w\", fill=False,\n",
    "                          edgecolor='none', linewidth=0)\n",
    "    ax.legend([extra], [scores], loc='upper left')\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 随机森林"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_theta_max = RandomForestRegressor()\n",
    "rfr_theta_avg = RandomForestRegressor()\n",
    "rfr_a_max = RandomForestRegressor()\n",
    "rfr_a_avg = RandomForestRegressor()\n",
    "\n",
    "# 贝叶斯优化\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "param_grid = {'max_depth': np.linspace(start=10, stop=500, num=50, dtype=int),\n",
    "              'n_estimators': np.arange(start=50, stop=1000, step=50, dtype=int),\n",
    "              'min_samples_leaf': np.array([2, 5, 10, 15], dtype=int),\n",
    "              'min_samples_split': np.array([2, 5, 10, 15], dtype=int),\n",
    "              'random_state': [3]}\n",
    "\n",
    "opt_theta_max = BayesSearchCV(rfr_theta_max, param_grid, n_iter=30, n_jobs=3, cv=3)\n",
    "opt_theta_avg = BayesSearchCV(rfr_theta_avg, param_grid, n_iter=30, n_jobs=3, cv=3)\n",
    "opt_a_max = BayesSearchCV(rfr_a_max, param_grid, n_iter=30, n_jobs=3, cv=3)\n",
    "opt_a_avg = BayesSearchCV(rfr_a_avg, param_grid, n_iter=30, n_jobs=3, cv=3)\n",
    "\n",
    "opt_theta_max.fit(new_X_train, y_train_theta_max)\n",
    "opt_theta_avg.fit(new_X_train, y_train_theta_avg)\n",
    "opt_a_max.fit(new_X_train, y_train_a_max)\n",
    "opt_a_avg.fit(new_X_train, y_train_a_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params_theta_max = opt_theta_max.best_params_\n",
    "best_params_theta_max"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params_theta_avg = opt_theta_avg.best_params_\n",
    "best_params_theta_avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params_a_max = opt_a_max.best_params_\n",
    "best_params_a_max"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params_a_avg = opt_a_avg.best_params_\n",
    "best_params_a_avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### theta_max"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfr_theta_max = RandomForestRegressor(max_depth=best_params_theta_max[\"max_depth\"],\n",
    "                                      n_estimators=best_params_theta_max[\"n_estimators\"],\n",
    "                                      min_samples_leaf=best_params_theta_max[\"min_samples_leaf\"],\n",
    "                                      min_samples_split=best_params_theta_max[\"min_samples_split\"],\n",
    "                                      random_state=best_params_theta_max[\"random_state\"]\n",
    "                                      )\n",
    "rfr_theta_max.fit(new_X_train, y_train_theta_max)\n",
    "\n",
    "train_pred_theta_max = rfr_theta_max.predict(new_X_train)\n",
    "pred_theta_max = rfr_theta_max.predict(new_X_test)\n",
    "print(rmsle(y_train_theta_max, train_pred_theta_max))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_theta_max = r2_score(y_test_theta_max, pred_theta_max)\n",
    "mse_theta_max = mean_squared_error(y_test_theta_max, pred_theta_max)\n",
    "mape_theta_max = mean_absolute_percentage_error(y_test_theta_max, pred_theta_max)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_theta_max, pred_theta_max,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_theta_max, mse_theta_max, mape_theta_max))\n",
    "\n",
    "main_features = plot_features_importances(rfr_theta_max.feature_importances_, x_label)\n",
    "\n",
    "# 使用主特征\n",
    "X_main = df_ok.loc[:, main_features].values\n",
    "X_main_train, X_main_test, y_train, y_test = train_test_split(X_main, y, test_size=0.1, random_state=2)\n",
    "print(X_main_train.shape, X_main_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# y_train_theta_max = y_train[:, 0]\n",
    "# y_test_theta_max = y_test[:, 0]\n",
    "\n",
    "new_X_main_train = X_main_train\n",
    "new_X_main_test = X_main_test\n",
    "\n",
    "ss_main = StandardScaler().fit(new_X_main_train)\n",
    "new_X_main_train = ss_main.transform(new_X_main_train)\n",
    "new_X_main_test = ss_main.transform(new_X_main_test)\n",
    "\n",
    "rfr_theta_max = RandomForestRegressor(max_depth=best_params_theta_max[\"max_depth\"],\n",
    "                                      n_estimators=best_params_theta_max[\"n_estimators\"],\n",
    "                                      min_samples_leaf=best_params_theta_max[\"min_samples_leaf\"],\n",
    "                                      min_samples_split=best_params_theta_max[\"min_samples_split\"],\n",
    "                                      random_state=best_params_theta_max[\"random_state\"]\n",
    "                                      )\n",
    "rfr_theta_max.fit(new_X_main_train, y_train_theta_max)\n",
    "\n",
    "train_pred_theta_max = rfr_theta_max.predict(new_X_main_train)\n",
    "pred_theta_max = rfr_theta_max.predict(new_X_main_test)\n",
    "print(rmsle(y_train_theta_max, train_pred_theta_max))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_theta_max = r2_score(y_test_theta_max, pred_theta_max)\n",
    "mse_theta_max = mean_squared_error(y_test_theta_max, pred_theta_max)\n",
    "mape_theta_max = mean_absolute_percentage_error(y_test_theta_max, pred_theta_max)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_theta_max, pred_theta_max,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_theta_max, mse_theta_max, mape_theta_max))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### theta_avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfr_theta_avg = RandomForestRegressor(max_depth=best_params_theta_avg[\"max_depth\"],\n",
    "                                      n_estimators=best_params_theta_avg[\"n_estimators\"],\n",
    "                                      min_samples_leaf=best_params_theta_avg[\"min_samples_leaf\"],\n",
    "                                      min_samples_split=best_params_theta_avg[\"min_samples_split\"],\n",
    "                                      random_state=best_params_theta_avg[\"random_state\"]\n",
    "                                      )\n",
    "rfr_theta_avg.fit(new_X_train, y_train_theta_avg)\n",
    "\n",
    "train_pred_theta_avg = rfr_theta_avg.predict(new_X_train)\n",
    "pred_theta_avg = rfr_theta_avg.predict(new_X_test)\n",
    "print(rmsle(y_train_theta_avg, train_pred_theta_avg))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_theta_avg = r2_score(y_test_theta_avg, pred_theta_avg)\n",
    "mse_theta_avg = mean_squared_error(y_test_theta_avg, pred_theta_avg)\n",
    "mape_theta_avg = mean_absolute_percentage_error(y_test_theta_avg, pred_theta_avg)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_theta_avg, pred_theta_avg,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_theta_avg, mse_theta_avg, mape_theta_avg))\n",
    "\n",
    "main_features = plot_features_importances(rfr_theta_avg.feature_importances_, x_label)\n",
    "\n",
    "# 使用主特征\n",
    "X_main = df_ok.loc[:, main_features].values\n",
    "X_main_train, X_main_test, y_train, y_test = train_test_split(X_main, y, test_size=0.1, random_state=2)\n",
    "print(X_main_train.shape, X_main_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# y_train_theta_avg = y_train[:, 1]\n",
    "# y_test_theta_avg = y_test[:, 1]\n",
    "\n",
    "new_X_main_train = X_main_train\n",
    "new_X_main_test = X_main_test\n",
    "\n",
    "ss_main = StandardScaler().fit(new_X_main_train)\n",
    "new_X_main_train = ss_main.transform(new_X_main_train)\n",
    "new_X_main_test = ss_main.transform(new_X_main_test)\n",
    "\n",
    "rfr_theta_avg = RandomForestRegressor(max_depth=best_params_theta_avg[\"max_depth\"],\n",
    "                                      n_estimators=best_params_theta_avg[\"n_estimators\"],\n",
    "                                      min_samples_leaf=best_params_theta_avg[\"min_samples_leaf\"],\n",
    "                                      min_samples_split=best_params_theta_avg[\"min_samples_split\"],\n",
    "                                      random_state=best_params_theta_avg[\"random_state\"]\n",
    "                                      )\n",
    "rfr_theta_avg.fit(new_X_main_train, y_train_theta_avg)\n",
    "\n",
    "train_pred_theta_avg = rfr_theta_avg.predict(new_X_main_train)\n",
    "pred_theta_avg = rfr_theta_avg.predict(new_X_main_test)\n",
    "print(rmsle(y_train_theta_avg, train_pred_theta_avg))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_theta_avg = r2_score(y_test_theta_avg, pred_theta_avg)\n",
    "mse_theta_avg = mean_squared_error(y_test_theta_avg, pred_theta_avg)\n",
    "mape_theta_avg = mean_absolute_percentage_error(y_test_theta_avg, pred_theta_avg)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_theta_avg, pred_theta_avg,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_theta_avg, mse_theta_avg, mape_theta_avg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a_max"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfr_a_max = RandomForestRegressor(max_depth=best_params_a_max[\"max_depth\"],\n",
    "                                  n_estimators=best_params_a_max[\"n_estimators\"],\n",
    "                                  min_samples_leaf=best_params_a_max[\"min_samples_leaf\"],\n",
    "                                  min_samples_split=best_params_a_max[\"min_samples_split\"],\n",
    "                                  random_state=best_params_a_max[\"random_state\"]\n",
    "                                  )\n",
    "rfr_a_max.fit(new_X_train, y_train_a_max)\n",
    "\n",
    "train_pred_a_max = rfr_a_max.predict(new_X_train)\n",
    "pred_a_max = rfr_a_max.predict(new_X_test)\n",
    "print(rmsle(y_train_a_max, train_pred_a_max))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_a_max = r2_score(y_test_a_max, pred_a_max)\n",
    "mse_a_max = mean_squared_error(y_test_a_max, pred_a_max)\n",
    "mape_a_max = mean_absolute_percentage_error(y_test_a_max, pred_a_max)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_a_max, pred_a_max,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_a_max, mse_a_max, mape_a_max))\n",
    "\n",
    "main_features = plot_features_importances(rfr_a_max.feature_importances_, x_label)\n",
    "\n",
    "# 使用主特征\n",
    "X_main = df_ok.loc[:, main_features].values\n",
    "X_main_train, X_main_test, y_train, y_test = train_test_split(X_main, y, test_size=0.1, random_state=2)\n",
    "print(X_main_train.shape, X_main_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# y_train_a_max = y_train[:, 2]\n",
    "# y_test_a_max = y_test[:, 2]\n",
    "\n",
    "new_X_main_train = X_main_train\n",
    "new_X_main_test = X_main_test\n",
    "\n",
    "ss_main = StandardScaler().fit(new_X_main_train)\n",
    "new_X_main_train = ss_main.transform(new_X_main_train)\n",
    "new_X_main_test = ss_main.transform(new_X_main_test)\n",
    "\n",
    "rfr_a_max = RandomForestRegressor(max_depth=best_params_a_max[\"max_depth\"],\n",
    "                                  n_estimators=best_params_a_max[\"n_estimators\"],\n",
    "                                  min_samples_leaf=best_params_a_max[\"min_samples_leaf\"],\n",
    "                                  min_samples_split=best_params_a_max[\"min_samples_split\"],\n",
    "                                  random_state=best_params_a_max[\"random_state\"]\n",
    "                                  )\n",
    "rfr_a_max.fit(new_X_main_train, y_train_a_max)\n",
    "\n",
    "train_pred_a_max = rfr_a_max.predict(new_X_main_train)\n",
    "pred_a_max = rfr_a_max.predict(new_X_main_test)\n",
    "print(rmsle(y_train_a_max, train_pred_a_max))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_a_max = r2_score(y_test_a_max, pred_a_max)\n",
    "mse_a_max = mean_squared_error(y_test_a_max, pred_a_max)\n",
    "mape_a_max = mean_absolute_percentage_error(y_test_a_max, pred_a_max)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_a_max, pred_a_max,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_a_max, mse_a_max, mape_a_max))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a_avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfr_a_avg = RandomForestRegressor(max_depth=best_params_a_avg[\"max_depth\"],\n",
    "                                  n_estimators=best_params_a_avg[\"n_estimators\"],\n",
    "                                  min_samples_leaf=best_params_a_avg[\"min_samples_leaf\"],\n",
    "                                  min_samples_split=best_params_a_avg[\"min_samples_split\"],\n",
    "                                  random_state=best_params_a_avg[\"random_state\"]\n",
    "                                  )\n",
    "rfr_a_avg.fit(new_X_train, y_train_a_avg)\n",
    "\n",
    "train_pred_a_avg = rfr_a_avg.predict(new_X_train)\n",
    "pred_a_avg = rfr_a_avg.predict(new_X_test)\n",
    "print(rmsle(y_train_a_avg, train_pred_a_avg))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_a_avg = r2_score(y_test_a_avg, pred_a_avg)\n",
    "mse_a_avg = mean_squared_error(y_test_a_avg, pred_a_avg)\n",
    "mape_a_avg = mean_absolute_percentage_error(y_test_a_avg, pred_a_avg)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_a_avg, pred_a_avg,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_a_avg, mse_a_avg, mape_a_avg))\n",
    "\n",
    "main_features = plot_features_importances(rfr_a_avg.feature_importances_, x_label)\n",
    "\n",
    "# 使用主特征\n",
    "X_main = df_ok.loc[:, main_features].values\n",
    "X_main_train, X_main_test, y_train, y_test = train_test_split(X_main, y, test_size=0.1, random_state=2)\n",
    "print(X_main_train.shape, X_main_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# y_train_a_avg = y_train[:, 3]\n",
    "# y_test_a_avg = y_test[:, 3]\n",
    "\n",
    "new_X_main_train = X_main_train\n",
    "new_X_main_test = X_main_test\n",
    "\n",
    "ss_main = StandardScaler().fit(new_X_main_train)\n",
    "new_X_main_train = ss_main.transform(new_X_main_train)\n",
    "new_X_main_test = ss_main.transform(new_X_main_test)\n",
    "\n",
    "rfr_a_avg = RandomForestRegressor(max_depth=best_params_a_avg[\"max_depth\"],\n",
    "                                  n_estimators=best_params_a_avg[\"n_estimators\"],\n",
    "                                  min_samples_leaf=best_params_a_avg[\"min_samples_leaf\"],\n",
    "                                  min_samples_split=best_params_a_avg[\"min_samples_split\"],\n",
    "                                  random_state=best_params_a_avg[\"random_state\"]\n",
    "                                  )\n",
    "rfr_a_avg.fit(new_X_main_train, y_train_a_avg)\n",
    "\n",
    "train_pred_a_avg = rfr_a_avg.predict(new_X_main_train)\n",
    "pred_a_avg = rfr_a_avg.predict(new_X_main_test)\n",
    "print(rmsle(y_train_a_avg, train_pred_a_avg))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_a_avg = r2_score(y_test_a_avg, pred_a_avg)\n",
    "mse_a_avg = mean_squared_error(y_test_a_avg, pred_a_avg)\n",
    "mape_a_avg = mean_absolute_percentage_error(y_test_a_avg, pred_a_avg)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_a_avg, pred_a_avg,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_a_avg, mse_a_avg, mape_a_avg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgbr_theta_max = XGBRegressor()\n",
    "xgbr_theta_avg = XGBRegressor()\n",
    "xgbr_a_max = XGBRegressor()\n",
    "xgbr_a_avg = XGBRegressor()\n",
    "\n",
    "# 贝叶斯优化\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "param_grid = {'learning_rate': np.array([0.01, 0.015, 0.025, 0.05, 0.1], dtype=float),\n",
    "              'gamma': np.array([0, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9, 1], dtype=float),\n",
    "              \"reg_alpha\": np.array([0, 0.01, 0.1, 1], dtype=float),\n",
    "              \"reg_lambda\": np.array([0, 0.1, 0.5, 1], dtype=float),\n",
    "              \"min_child_weight\": np.array([1, 3, 5, 7], dtype=int),\n",
    "              \"colsample_bytree\": np.array([0.5, 0.6, 0.7, 0.8, 0.9, 1], dtype=float),\n",
    "              'subsample': np.array([0.5, 0.6, 0.7, 0.8, 0.9, 1], dtype=float),\n",
    "              'max_depth': np.array([3, 5, 8, 15, 25, 30], dtype=int),\n",
    "              'n_estimators': np.linspace(start=50, stop=3000, num=60, dtype=int),\n",
    "              'random_state': [3]}\n",
    "\n",
    "opt_theta_max = BayesSearchCV(xgbr_theta_max, param_grid, n_iter=30, n_jobs=3, cv=3)\n",
    "opt_theta_avg = BayesSearchCV(xgbr_theta_avg, param_grid, n_iter=30, n_jobs=3, cv=3)\n",
    "opt_a_max = BayesSearchCV(xgbr_a_max, param_grid, n_iter=30, n_jobs=3, cv=3)\n",
    "opt_a_avg = BayesSearchCV(xgbr_a_avg, param_grid, n_iter=30, n_jobs=3, cv=3)\n",
    "\n",
    "opt_theta_max.fit(new_X_train, y_train_theta_max)\n",
    "opt_theta_avg.fit(new_X_train, y_train_theta_avg)\n",
    "opt_a_max.fit(new_X_train, y_train_a_max)\n",
    "opt_a_avg.fit(new_X_train, y_train_a_avg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params_theta_max = opt_theta_max.best_params_\n",
    "best_params_theta_max"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params_theta_avg = opt_theta_avg.best_params_\n",
    "best_params_theta_avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params_a_max = opt_a_max.best_params_\n",
    "best_params_a_max"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params_a_avg = opt_a_avg.best_params_\n",
    "best_params_a_avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### theta_max"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgbr_theta_max = XGBRegressor(n_estimators=best_params_theta_max[\"n_estimators\"],\n",
    "                              colsample_bytree=best_params_theta_max['colsample_bytree'],\n",
    "                              max_depth=best_params_theta_max[\"max_depth\"],\n",
    "                              learning_rate=best_params_theta_max[\"learning_rate\"],\n",
    "                              gamma=best_params_theta_max[\"gamma\"],\n",
    "                              min_child_weight=best_params_theta_max[\"min_child_weight\"],\n",
    "                              reg_alpha=best_params_theta_max[\"reg_alpha\"],\n",
    "                              reg_lambda=best_params_theta_max[\"reg_lambda\"],\n",
    "                              subsample=best_params_theta_max[\"subsample\"],\n",
    "                              random_state=best_params_theta_max[\"random_state\"])\n",
    "xgbr_theta_max.fit(new_X_train, y_train_theta_max)\n",
    "\n",
    "train_pred_theta_max = xgbr_theta_max.predict(new_X_train)\n",
    "pred_theta_max = xgbr_theta_max.predict(new_X_test)\n",
    "print(rmsle(y_train_theta_max, train_pred_theta_max))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_theta_max = r2_score(y_test_theta_max, pred_theta_max)\n",
    "mse_theta_max = mean_squared_error(y_test_theta_max, pred_theta_max)\n",
    "mape_theta_max = mean_absolute_percentage_error(y_test_theta_max, pred_theta_max)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_theta_max, pred_theta_max,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_theta_max, mse_theta_max, mape_theta_max))\n",
    "\n",
    "main_features = plot_features_importances(xgbr_theta_max.feature_importances_, x_label)\n",
    "\n",
    "# 使用主特征\n",
    "X_main = df_ok.loc[:, main_features].values\n",
    "X_main_train, X_main_test, y_train, y_test = train_test_split(X_main, y, test_size=0.1, random_state=2)\n",
    "print(X_main_train.shape, X_main_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "new_X_main_train = X_main_train\n",
    "new_X_main_test = X_main_test\n",
    "\n",
    "ss_main = StandardScaler().fit(new_X_main_train)\n",
    "new_X_main_train = ss_main.transform(new_X_main_train)\n",
    "new_X_main_test = ss_main.transform(new_X_main_test)\n",
    "\n",
    "xgbr_theta_max = XGBRegressor(n_estimators=best_params_theta_max[\"n_estimators\"],\n",
    "                              colsample_bytree=best_params_theta_max['colsample_bytree'],\n",
    "                              max_depth=best_params_theta_max[\"max_depth\"],\n",
    "                              learning_rate=best_params_theta_max[\"learning_rate\"],\n",
    "                              gamma=best_params_theta_max[\"gamma\"],\n",
    "                              min_child_weight=best_params_theta_max[\"min_child_weight\"],\n",
    "                              reg_alpha=best_params_theta_max[\"reg_alpha\"],\n",
    "                              reg_lambda=best_params_theta_max[\"reg_lambda\"],\n",
    "                              subsample=best_params_theta_max[\"subsample\"],\n",
    "                              random_state=best_params_theta_max[\"random_state\"])\n",
    "xgbr_theta_max.fit(new_X_main_train, y_train_theta_max)\n",
    "\n",
    "train_pred_theta_max = xgbr_theta_max.predict(new_X_main_train)\n",
    "pred_theta_max = xgbr_theta_max.predict(new_X_main_test)\n",
    "print(rmsle(y_train_theta_max, train_pred_theta_max))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_theta_max = r2_score(y_test_theta_max, pred_theta_max)\n",
    "mse_theta_max = mean_squared_error(y_test_theta_max, pred_theta_max)\n",
    "mape_theta_max = mean_absolute_percentage_error(y_test_theta_max, pred_theta_max)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_theta_max, pred_theta_max,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_theta_max, mse_theta_max, mape_theta_max))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### theta_avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgbr_theta_avg = XGBRegressor(n_estimators=best_params_theta_avg[\"n_estimators\"],\n",
    "                              colsample_bytree=best_params_theta_avg['colsample_bytree'],\n",
    "                              max_depth=best_params_theta_avg[\"max_depth\"],\n",
    "                              learning_rate=best_params_theta_avg[\"learning_rate\"],\n",
    "                              gamma=best_params_theta_avg[\"gamma\"],\n",
    "                              min_child_weight=best_params_theta_avg[\"min_child_weight\"],\n",
    "                              reg_alpha=best_params_theta_avg[\"reg_alpha\"],\n",
    "                              reg_lambda=best_params_theta_avg[\"reg_lambda\"],\n",
    "                              subsample=best_params_theta_avg[\"subsample\"],\n",
    "                              random_state=best_params_theta_avg[\"random_state\"])\n",
    "xgbr_theta_avg.fit(new_X_train, y_train_theta_avg)\n",
    "\n",
    "train_pred_theta_avg = xgbr_theta_avg.predict(new_X_train)\n",
    "pred_theta_avg = xgbr_theta_avg.predict(new_X_test)\n",
    "print(rmsle(y_train_theta_avg, train_pred_theta_avg))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_theta_avg = r2_score(y_test_theta_avg, pred_theta_avg)\n",
    "mse_theta_avg = mean_squared_error(y_test_theta_avg, pred_theta_avg)\n",
    "mape_theta_avg = mean_absolute_percentage_error(y_test_theta_avg, pred_theta_avg)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_theta_avg, pred_theta_avg,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_theta_avg, mse_theta_avg, mape_theta_avg))\n",
    "\n",
    "main_features = plot_features_importances(xgbr_theta_avg.feature_importances_, x_label)\n",
    "\n",
    "# 使用主特征\n",
    "X_main = df_ok.loc[:, main_features].values\n",
    "X_main_train, X_main_test, y_train, y_test = train_test_split(X_main, y, test_size=0.1, random_state=2)\n",
    "print(X_main_train.shape, X_main_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "new_X_main_train = X_main_train\n",
    "new_X_main_test = X_main_test\n",
    "\n",
    "ss_main = StandardScaler().fit(new_X_main_train)\n",
    "new_X_main_train = ss_main.transform(new_X_main_train)\n",
    "new_X_main_test = ss_main.transform(new_X_main_test)\n",
    "\n",
    "xgbr_theta_avg = XGBRegressor(n_estimators=best_params_theta_avg[\"n_estimators\"],\n",
    "                              colsample_bytree=best_params_theta_avg['colsample_bytree'],\n",
    "                              max_depth=best_params_theta_avg[\"max_depth\"],\n",
    "                              learning_rate=best_params_theta_avg[\"learning_rate\"],\n",
    "                              gamma=best_params_theta_avg[\"gamma\"],\n",
    "                              min_child_weight=best_params_theta_avg[\"min_child_weight\"],\n",
    "                              reg_alpha=best_params_theta_avg[\"reg_alpha\"],\n",
    "                              reg_lambda=best_params_theta_avg[\"reg_lambda\"],\n",
    "                              subsample=best_params_theta_avg[\"subsample\"],\n",
    "                              random_state=best_params_theta_avg[\"random_state\"])\n",
    "xgbr_theta_avg.fit(new_X_main_train, y_train_theta_avg)\n",
    "\n",
    "train_pred_theta_avg = xgbr_theta_avg.predict(new_X_main_train)\n",
    "pred_theta_avg = xgbr_theta_avg.predict(new_X_main_test)\n",
    "print(rmsle(y_train_theta_avg, train_pred_theta_avg))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_theta_avg = r2_score(y_test_theta_avg, pred_theta_avg)\n",
    "mse_theta_avg = mean_squared_error(y_test_theta_avg, pred_theta_avg)\n",
    "mape_theta_avg = mean_absolute_percentage_error(y_test_theta_avg, pred_theta_avg)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_theta_avg, pred_theta_avg,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_theta_avg, mse_theta_avg, mape_theta_avg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a_max"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgbr_a_max = XGBRegressor(n_estimators=best_params_a_max[\"n_estimators\"],\n",
    "                          colsample_bytree=best_params_a_max['colsample_bytree'],\n",
    "                          max_depth=best_params_a_max[\"max_depth\"],\n",
    "                          learning_rate=best_params_a_max[\"learning_rate\"],\n",
    "                          gamma=best_params_a_max[\"gamma\"],\n",
    "                          min_child_weight=best_params_a_max[\"min_child_weight\"],\n",
    "                          reg_alpha=best_params_a_max[\"reg_alpha\"],\n",
    "                          reg_lambda=best_params_a_max[\"reg_lambda\"],\n",
    "                          subsample=best_params_a_max[\"subsample\"],\n",
    "                          random_state=best_params_a_max[\"random_state\"])\n",
    "xgbr_a_max.fit(new_X_train, y_train_a_max)\n",
    "\n",
    "train_pred_a_max = xgbr_a_max.predict(new_X_train)\n",
    "pred_a_max = xgbr_a_max.predict(new_X_test)\n",
    "print(rmsle(y_train_a_max, train_pred_a_max))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_a_max = r2_score(y_test_a_max, pred_a_max)\n",
    "mse_a_max = mean_squared_error(y_test_a_max, pred_a_max)\n",
    "mape_a_max = mean_absolute_percentage_error(y_test_a_max, pred_a_max)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_a_max, pred_a_max,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_a_max, mse_a_max, mape_a_max))\n",
    "\n",
    "main_features = plot_features_importances(xgbr_a_max.feature_importances_, x_label)\n",
    "\n",
    "# 使用主特征\n",
    "X_main = df_ok.loc[:, main_features].values\n",
    "X_main_train, X_main_test, y_train, y_test = train_test_split(X_main, y, test_size=0.1, random_state=2)\n",
    "print(X_main_train.shape, X_main_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "new_X_main_train = X_main_train\n",
    "new_X_main_test = X_main_test\n",
    "\n",
    "ss_main = StandardScaler().fit(new_X_main_train)\n",
    "new_X_main_train = ss_main.transform(new_X_main_train)\n",
    "new_X_main_test = ss_main.transform(new_X_main_test)\n",
    "\n",
    "xgbr_a_max = XGBRegressor(n_estimators=best_params_a_max[\"n_estimators\"],\n",
    "                          colsample_bytree=best_params_a_max['colsample_bytree'],\n",
    "                          max_depth=best_params_a_max[\"max_depth\"],\n",
    "                          learning_rate=best_params_a_max[\"learning_rate\"],\n",
    "                          gamma=best_params_a_max[\"gamma\"],\n",
    "                          min_child_weight=best_params_a_max[\"min_child_weight\"],\n",
    "                          reg_alpha=best_params_a_max[\"reg_alpha\"],\n",
    "                          reg_lambda=best_params_a_max[\"reg_lambda\"],\n",
    "                          subsample=best_params_a_max[\"subsample\"],\n",
    "                          random_state=best_params_a_max[\"random_state\"])\n",
    "xgbr_a_max.fit(new_X_main_train, y_train_a_max)\n",
    "\n",
    "train_pred_a_max = xgbr_a_max.predict(new_X_main_train)\n",
    "pred_a_max = xgbr_a_max.predict(new_X_main_test)\n",
    "print(rmsle(y_train_a_max, train_pred_a_max))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_a_max = r2_score(y_test_a_max, pred_a_max)\n",
    "mse_a_max = mean_squared_error(y_test_a_max, pred_a_max)\n",
    "mape_a_max = mean_absolute_percentage_error(y_test_a_max, pred_a_max)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_a_max, pred_a_max,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_a_max, mse_a_max, mape_a_max))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a_avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgbr_a_avg = XGBRegressor(n_estimators=best_params_a_avg[\"n_estimators\"],\n",
    "                          colsample_bytree=best_params_a_avg['colsample_bytree'],\n",
    "                          max_depth=best_params_a_avg[\"max_depth\"],\n",
    "                          learning_rate=best_params_a_avg[\"learning_rate\"],\n",
    "                          gamma=best_params_a_avg[\"gamma\"],\n",
    "                          min_child_weight=best_params_a_avg[\"min_child_weight\"],\n",
    "                          reg_alpha=best_params_a_avg[\"reg_alpha\"],\n",
    "                          reg_lambda=best_params_a_avg[\"reg_lambda\"],\n",
    "                          subsample=best_params_a_avg[\"subsample\"],\n",
    "                          random_state=best_params_a_avg[\"random_state\"])\n",
    "xgbr_a_avg.fit(new_X_train, y_train_a_avg)\n",
    "\n",
    "train_pred_a_avg = xgbr_a_avg.predict(new_X_train)\n",
    "pred_a_avg = xgbr_a_avg.predict(new_X_test)\n",
    "print(rmsle(y_train_a_avg, train_pred_a_avg))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_a_avg = r2_score(y_test_a_avg, pred_a_avg)\n",
    "mse_a_avg = mean_squared_error(y_test_a_avg, pred_a_avg)\n",
    "mape_a_avg = mean_absolute_percentage_error(y_test_a_avg, pred_a_avg)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_a_avg, pred_a_avg,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_a_avg, mse_a_avg, mape_a_avg))\n",
    "\n",
    "main_features = plot_features_importances(xgbr_a_avg.feature_importances_, x_label)\n",
    "\n",
    "# 使用主特征\n",
    "X_main = df_ok.loc[:, main_features].values\n",
    "X_main_train, X_main_test, y_train, y_test = train_test_split(X_main, y, test_size=0.1, random_state=2)\n",
    "print(X_main_train.shape, X_main_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "new_X_main_train = X_main_train\n",
    "new_X_main_test = X_main_test\n",
    "\n",
    "ss_main = StandardScaler().fit(new_X_main_train)\n",
    "new_X_main_train = ss_main.transform(new_X_main_train)\n",
    "new_X_main_test = ss_main.transform(new_X_main_test)\n",
    "\n",
    "xgbr_a_avg = XGBRegressor(n_estimators=best_params_a_avg[\"n_estimators\"],\n",
    "                          colsample_bytree=best_params_a_avg['colsample_bytree'],\n",
    "                          max_depth=best_params_a_avg[\"max_depth\"],\n",
    "                          learning_rate=best_params_a_avg[\"learning_rate\"],\n",
    "                          gamma=best_params_a_avg[\"gamma\"],\n",
    "                          min_child_weight=best_params_a_avg[\"min_child_weight\"],\n",
    "                          reg_alpha=best_params_a_avg[\"reg_alpha\"],\n",
    "                          reg_lambda=best_params_a_avg[\"reg_lambda\"],\n",
    "                          subsample=best_params_a_avg[\"subsample\"],\n",
    "                          random_state=best_params_a_avg[\"random_state\"])\n",
    "xgbr_a_avg.fit(new_X_main_train, y_train_a_avg)\n",
    "\n",
    "train_pred_a_avg = xgbr_a_avg.predict(new_X_main_train)\n",
    "pred_a_avg = xgbr_a_avg.predict(new_X_main_test)\n",
    "print(rmsle(y_train_a_avg, train_pred_a_avg))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "r2_a_avg = r2_score(y_test_a_avg, pred_a_avg)\n",
    "mse_a_avg = mean_squared_error(y_test_a_avg, pred_a_avg)\n",
    "mape_a_avg = mean_absolute_percentage_error(y_test_a_avg, pred_a_avg)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plot_regression_results(\n",
    "    ax, y_test_a_avg, pred_a_avg,\n",
    "    \"Stacking Regressor\",\n",
    "    (r'$R^2={:.2f}$' + '\\n' + r'$MAPE={:.2f}$' + '\\n' + r'$MSE={:.2f}$')\n",
    "    .format(r2_a_avg, mse_a_avg, mape_a_avg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
